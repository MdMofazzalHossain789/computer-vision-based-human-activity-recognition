{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6826584,"sourceType":"datasetVersion","datasetId":3925445}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:28.779099Z","iopub.execute_input":"2025-06-26T17:42:28.779806Z","iopub.status.idle":"2025-06-26T17:42:28.783075Z","shell.execute_reply.started":"2025-06-26T17:42:28.779782Z","shell.execute_reply":"2025-06-26T17:42:28.782394Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Specify the directory containing the UCF50 dataset\nDATASET_DIR = \"/kaggle/input/realistic-action-recognition-ucf50/UCF50\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:28.787588Z","iopub.execute_input":"2025-06-26T17:42:28.787765Z","iopub.status.idle":"2025-06-26T17:42:28.801677Z","shell.execute_reply.started":"2025-06-26T17:42:28.787752Z","shell.execute_reply":"2025-06-26T17:42:28.801178Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"!ls \"/kaggle/input/realistic-action-recognition-ucf50/UCF50\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:28.802750Z","iopub.execute_input":"2025-06-26T17:42:28.802987Z","iopub.status.idle":"2025-06-26T17:42:28.943386Z","shell.execute_reply.started":"2025-06-26T17:42:28.802967Z","shell.execute_reply":"2025-06-26T17:42:28.942709Z"}},"outputs":[{"name":"stdout","text":"BaseballPitch  HorseRiding     PlayingPiano\t   Skiing\nBasketball     HulaHoop        PlayingTabla\t   Skijet\nBenchPress     JavelinThrow    PlayingViolin\t   SoccerJuggling\nBiking\t       JugglingBalls   PoleVault\t   Swing\nBilliards      JumpingJack     PommelHorse\t   TaiChi\nBreastStroke   JumpRope        PullUps\t\t   TennisSwing\nCleanAndJerk   Kayaking        Punch\t\t   ThrowDiscus\nDiving\t       Lunges\t       PushUps\t\t   TrampolineJumping\nDrumming       MilitaryParade  RockClimbingIndoor  VolleyballSpiking\nFencing        Mixing\t       RopeClimbing\t   WalkingWithDog\nGolfSwing      Nunchucks       Rowing\t\t   YoYo\nHighJump       PizzaTossing    SalsaSpin\nHorseRace      PlayingGuitar   SkateBoarding\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"\ndef frames_extraction(video_path, sequence_length=20, image_height=224, image_width=224):\n    '''\n    This function extracts the required frames from a video, resizes and normalizes them for model input.\n    Args:\n        video_path: The path of the video in the disk, whose frames are to be extracted.\n        sequence_length: Number of frames to extract per video (default: 20).\n        image_height: Height to resize frames to (default: 224 for Xception).\n        image_width: Width to resize frames to (default: 224 for Xception).\n    Returns:\n        frames_list: A list containing the resized and normalized frames of the video, or None if extraction fails.\n    '''\n    # Declare a list to store video frames\n    frames_list = []\n\n    # Check if video file exists\n    if not os.path.exists(video_path):\n        print(f\"Error: Video file not found at {video_path}\")\n        return None\n\n    # Read the video file using VideoCapture\n    video_reader = cv2.VideoCapture(video_path)\n\n    # Check if the video was opened successfully\n    if not video_reader.isOpened():\n        print(f\"Error: Could not open video file {video_path}\")\n        video_reader.release()\n        return None\n\n    # Get the total number of frames in the video '30' -> 30\n    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n\n    # Ensure the video has enough frames\n    if video_frames_count < sequence_length:\n        print(f\"Warning: Video {video_path} has only {video_frames_count} frames, less than required {sequence_length}\")\n        video_reader.release()\n        return None\n\n    # Calculate the interval after which frames will be sampled\n    skip_frames_window = max(int(video_frames_count / sequence_length), 1)\n\n    # Iterate to extract the specified number of frames\n    # for 1 in range(20) 1...20\n    for frame_counter in range(sequence_length):\n        # Set the current frame position\n        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n        \n        # Read the frame\n        success, frame = video_reader.read()\n\n        # Check if the frame was read successfully\n        if not success or frame is None:\n            print(f\"Warning: Failed to read frame {frame_counter} from {video_path}\")\n            break\n\n        # Resize the frame to the specified dimensions\n        try:\n            resized_frame = cv2.resize(frame, (image_width, image_height))\n        except Exception as e:\n            print(f\"Error resizing frame {frame_counter} from {video_path}: {e}\")\n            break\n\n        # Normalize the frame to [0 - 1] for model input\n        normalized_frame = resized_frame / 255.0\n\n\n        # Append the normalized frame to the list\n        frames_list.append(normalized_frame)\n\n    # Release the VideoCapture object\n    video_reader.release()\n\n    # Ensure the correct number of frames is extracted\n    if len(frames_list) != sequence_length:\n        print(f\"Warning: Extracted {len(frames_list)} frames instead of {sequence_length} from {video_path}\")\n        return None\n\n    # Convert to numpy array for consistency\n    frames_list = np.array(frames_list)\n\n    return frames_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:28.945004Z","iopub.execute_input":"2025-06-26T17:42:28.945288Z","iopub.status.idle":"2025-06-26T17:42:28.954606Z","shell.execute_reply.started":"2025-06-26T17:42:28.945267Z","shell.execute_reply":"2025-06-26T17:42:28.953852Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"frames_extraction(\"/kaggle/input/realistic-action-recognition-ucf50/UCF50/BaseballPitch/v_BaseballPitch_g01_c01.avi\")\n\nprint(\"Next Create Dataset...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:28.955325Z","iopub.execute_input":"2025-06-26T17:42:28.955557Z","iopub.status.idle":"2025-06-26T17:42:29.293130Z","shell.execute_reply.started":"2025-06-26T17:42:28.955532Z","shell.execute_reply":"2025-06-26T17:42:29.292316Z"}},"outputs":[{"name":"stdout","text":"Next Create Dataset...\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# does exist or not?\n# /kaggle/input/realistic-action-recognition-ucf50/UCF50\nos.path.exists('/kaggle/input/UCF50')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:29.295006Z","iopub.execute_input":"2025-06-26T17:42:29.295409Z","iopub.status.idle":"2025-06-26T17:42:29.300271Z","shell.execute_reply.started":"2025-06-26T17:42:29.295391Z","shell.execute_reply":"2025-06-26T17:42:29.299623Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"Folder = \"Baseball\"\nFile = \"video 1.mp4\"\nDataset = \"/kaggle/input/realistic-action-recognition-ucf50/UCF50\"\n\npath = Dataset + \"/\" + Folder + \"/\" + File\n\nprint(\"Custom - \",path)\n\nos.path.join(Dataset, Folder, File)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:29.301132Z","iopub.execute_input":"2025-06-26T17:42:29.301408Z","iopub.status.idle":"2025-06-26T17:42:29.316553Z","shell.execute_reply.started":"2025-06-26T17:42:29.301385Z","shell.execute_reply":"2025-06-26T17:42:29.315816Z"}},"outputs":[{"name":"stdout","text":"Custom -  /kaggle/input/realistic-action-recognition-ucf50/UCF50/Baseball/video 1.mp4\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/realistic-action-recognition-ucf50/UCF50/Baseball/video 1.mp4'"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"# list direcotories\nDir = \"/kaggle/input/realistic-action-recognition-ucf50/UCF50/JumpRope\"\nos.listdir(Dir)\n\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:29.317196Z","iopub.execute_input":"2025-06-26T17:42:29.317376Z","iopub.status.idle":"2025-06-26T17:42:29.332714Z","shell.execute_reply.started":"2025-06-26T17:42:29.317361Z","shell.execute_reply":"2025-06-26T17:42:29.332005Z"}},"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"class_list = ['Jump', 'Sleep']\n\nfor index, Class in enumerate(class_list):\n    print(index, Class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:29.333457Z","iopub.execute_input":"2025-06-26T17:42:29.333686Z","iopub.status.idle":"2025-06-26T17:42:29.347245Z","shell.execute_reply.started":"2025-06-26T17:42:29.333671Z","shell.execute_reply":"2025-06-26T17:42:29.346647Z"}},"outputs":[{"name":"stdout","text":"0 Jump\n1 Sleep\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"numbers =[ number for number in range(0,50)]\n\nprint(numbers[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:29.347941Z","iopub.execute_input":"2025-06-26T17:42:29.348432Z","iopub.status.idle":"2025-06-26T17:42:29.368419Z","shell.execute_reply.started":"2025-06-26T17:42:29.348410Z","shell.execute_reply":"2025-06-26T17:42:29.367709Z"}},"outputs":[{"name":"stdout","text":"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"import os\nimport numpy as np\n\n# args = /kaggle/input/realistic-action-recognition-ucf50/UCF5O/JumpRope, ['JumpRop', 'Basketball'] seq, img hw\n\ndef create_dataset(dataset_dir, classes_list, sequence_length=20, image_height=224, image_width=224, max_videos_per_class=None):\n    '''\n    This function extracts data for selected classes and creates the dataset.\n    Args:\n        dataset_dir: The directory containing the UCF-50 dataset (e.g., \"/kaggle/working/UCF50_dataset/UCF50\").\n        classes_list: List of class names to include in the dataset.\n        sequence_length: Number of frames to extract per video (default: 20).\n        image_height: Height to resize frames to (default: 224 for Xception).\n        image_width: Width to resize frames to (default: 224 for Xception).\n        max_videos_per_class: Maximum number of videos to process per class (optional, for testing).\n    Returns:\n        features: A numpy array of extracted frame sequences with shape (n_videos, sequence_length, image_height, image_width, 3).\n        labels: A numpy array of class indexes.\n        video_files_paths: A list of video file paths.\n    '''\n    # /kaggle/input/realistic-action-recognition-ucf50/UCF50/BaseballPitch/v_BaseballPitch_g01_c01.avi\n    # Initialize lists to store features, labels, and video file paths\n    features = []\n    labels = []\n    video_files_paths = []\n\n    # Check if dataset directory exists\n    if not os.path.exists(dataset_dir):\n        raise FileNotFoundError(f\"Dataset directory not found: {dataset_dir}\")\n\n    # Iterate through all classes in the classes list\n    for class_index, class_name in enumerate(classes_list):\n        # dataset_dir + class name\n        class_path = os.path.join(dataset_dir, class_name)\n        \n        # Check if class directory exists\n        if not os.path.exists(class_path):\n            print(f\"Warning: Class directory not found: {class_path}\")\n            continue\n\n        print(f'Extracting Data of Class: {class_name}')\n\n        # Get the list of video files in the class directory\n        files_list = os.listdir(class_path)\n\n        # Limit the number of videos if specified 100\n        if max_videos_per_class is not None:\n            # files list = 140 -> 0-99\n            files_list = files_list[:max_videos_per_class]\n\n        # Iterate through all video files ['v1', 'v2']\n        for file_name in files_list:\n            # \n            video_file_path = os.path.join(class_path, file_name)\n\n            # Extract frames using the updated frames_extraction function\n            frames = frames_extraction(video_file_path, sequence_length, image_height, image_width)\n\n            # Skip videos where frame extraction failed\n            if frames is None:\n                print(f\"Skipping video {video_file_path} due to frame extraction failure\")\n                continue\n\n            # Append the data to respective lists\n            features.append(frames)\n            labels.append(class_index)\n            video_files_paths.append(video_file_path)\n\n    # Convert lists to numpy arrays\n    if not features:\n        raise ValueError(\"No valid videos were processed. Check dataset or parameters.\")\n    \n    features = np.asarray(features)\n    labels = np.array(labels)\n\n    print(f\"Dataset created with {len(features)} videos\")\n    print(f\"Features shape: {features.shape}\")\n    print(f\"Labels shape: {labels.shape}\")\n\n    return features, labels, video_files_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:42:29.369218Z","iopub.execute_input":"2025-06-26T17:42:29.369475Z","iopub.status.idle":"2025-06-26T17:42:29.383672Z","shell.execute_reply.started":"2025-06-26T17:42:29.369437Z","shell.execute_reply":"2025-06-26T17:42:29.382943Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"information = create_dataset(\"/kaggle/input/realistic-action-recognition-ucf50/UCF50\", ['Basketball', 'Biking'], 20,224,224)\n\nfeatures, labels, video_file_paths = information\n\nprint(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:44:42.833840Z","iopub.execute_input":"2025-06-26T17:44:42.834146Z","iopub.status.idle":"2025-06-26T17:45:07.178773Z","shell.execute_reply.started":"2025-06-26T17:44:42.834126Z","shell.execute_reply":"2025-06-26T17:45:07.177925Z"}},"outputs":[{"name":"stdout","text":"Extracting Data of Class: Basketball\nExtracting Data of Class: Biking\nDataset created with 282 videos\nFeatures shape: (282, 20, 224, 224, 3)\nLabels shape: (282,)\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","output_type":"stream"}],"execution_count":55}]}